"""
FraudGuard AI - Modelo de RegressÃ£o
Calcular Score de Risco (0-100) para cada transaÃ§Ã£o
"""

import matplotlib
matplotlib.use('Agg')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import Ridge, Lasso
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler
import joblib
import time
import warnings
warnings.filterwarnings('ignore')

print("="*80)
print(" "*22 + "FRAUDGUARD AI - MODELO DE REGRESSÃƒO")
print("="*80)

# ============================================
# 1. CARREGAR DADOS E PREPARAR TARGET
# ============================================
print("\nğŸ“‚ 1. CARREGANDO E PREPARANDO DADOS...")
print("-"*80)

try:
    df = pd.read_csv('datasets/fraud/creditcard_processed.csv')
except:
    df = pd.read_csv('datasets/fraud/creditcard.csv')
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    df['Amount_scaled'] = scaler.fit_transform(df['Amount'].values.reshape(-1, 1))
    df['Time_scaled'] = scaler.fit_transform(df['Time'].values.reshape(-1, 1))

print(f"âœ… Dados carregados: {len(df):,} transaÃ§Ãµes")

# Preparar features
X = df.drop(['Class', 'Amount', 'Time'], axis=1, errors='ignore')

# CRIAR TARGET: Score de Risco (0-100)
# Vamos usar a probabilidade do modelo de classificaÃ§Ã£o + features
print("\nğŸ¯ Criando Score de Risco...")

# Carregar modelo de classificaÃ§Ã£o treinado
clf_model = joblib.load('models/classification/fraud_classifier.pkl')

# Calcular probabilidades de fraude
fraud_probabilities = clf_model.predict_proba(X)[:, 1]

# Criar score base (0-100)
risk_score_base = fraud_probabilities * 100

# Adicionar fatores de risco baseados em features
# Exemplo: valores muito altos ou muito baixos aumentam risco
if 'Amount_scaled' in df.columns:
    amount_factor = np.abs(df['Amount_scaled']) * 5  # Valores extremos = mais risco
else:
    amount_factor = 0

# Score final (0-100)
y = np.clip(risk_score_base + amount_factor, 0, 100)

print(f"âœ… Score de Risco criado!")
print(f"   â€¢ MÃ©dia: {y.mean():.2f}")
print(f"   â€¢ Mediana: {np.median(y):.2f}")
print(f"   â€¢ Min: {y.min():.2f}, Max: {y.max():.2f}")
print(f"   â€¢ Desvio padrÃ£o: {y.std():.2f}")

# DistribuiÃ§Ã£o por classe
print(f"\nğŸ“Š Score por classe:")
print(f"   â€¢ LegÃ­timas (Class=0): {y[df['Class']==0].mean():.2f} Â± {y[df['Class']==0].std():.2f}")
print(f"   â€¢ Fraudes (Class=1):   {y[df['Class']==1].mean():.2f} Â± {y[df['Class']==1].std():.2f}")

# ============================================
# 2. DIVIDIR DADOS
# ============================================
print("\nğŸ”€ 2. DIVIDINDO DADOS EM TREINO E TESTE")
print("-"*80)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"âœ… Dados divididos:")
print(f"   Treino: {len(X_train):,} amostras")
print(f"   Teste:  {len(X_test):,} amostras")

# ============================================
# 3. TREINAR MODELOS DE REGRESSÃƒO
# ============================================
print("\nğŸ¤– 3. TREINANDO MODELOS DE REGRESSÃƒO")
print("-"*80)

models = {}
results = {}

# === MODELO 1: RANDOM FOREST REGRESSOR ===
print("\nğŸŒ² Treinando Random Forest Regressor...")
start_time = time.time()

rf_reg = RandomForestRegressor(
    n_estimators=100,
    max_depth=20,
    min_samples_split=10,
    min_samples_leaf=5,
    random_state=42,
    n_jobs=-1
)

rf_reg.fit(X_train, y_train)
rf_time = time.time() - start_time

print(f"âœ… Random Forest treinado em {rf_time:.2f}s")

# PrediÃ§Ãµes
y_pred_rf = rf_reg.predict(X_test)
y_pred_rf = np.clip(y_pred_rf, 0, 100)  # Garantir 0-100

# MÃ©tricas
results['Random Forest'] = {
    'model': rf_reg,
    'predictions': y_pred_rf,
    'mse': mean_squared_error(y_test, y_pred_rf),
    'rmse': np.sqrt(mean_squared_error(y_test, y_pred_rf)),
    'mae': mean_absolute_error(y_test, y_pred_rf),
    'r2': r2_score(y_test, y_pred_rf),
    'time': rf_time
}

# === MODELO 2: GRADIENT BOOSTING ===
print("\nâš¡ Treinando Gradient Boosting Regressor...")
start_time = time.time()

gb_reg = GradientBoostingRegressor(
    n_estimators=100,
    max_depth=10,
    learning_rate=0.1,
    random_state=42
)

gb_reg.fit(X_train, y_train)
gb_time = time.time() - start_time

print(f"âœ… Gradient Boosting treinado em {gb_time:.2f}s")

# PrediÃ§Ãµes
y_pred_gb = gb_reg.predict(X_test)
y_pred_gb = np.clip(y_pred_gb, 0, 100)

# MÃ©tricas
results['Gradient Boosting'] = {
    'model': gb_reg,
    'predictions': y_pred_gb,
    'mse': mean_squared_error(y_test, y_pred_gb),
    'rmse': np.sqrt(mean_squared_error(y_test, y_pred_gb)),
    'mae': mean_absolute_error(y_test, y_pred_gb),
    'r2': r2_score(y_test, y_pred_gb),
    'time': gb_time
}

# === MODELO 3: RIDGE REGRESSION ===
print("\nğŸ“Š Treinando Ridge Regression...")
start_time = time.time()

ridge_reg = Ridge(alpha=1.0, random_state=42)

ridge_reg.fit(X_train, y_train)
ridge_time = time.time() - start_time

print(f"âœ… Ridge Regression treinado em {ridge_time:.2f}s")

# PrediÃ§Ãµes
y_pred_ridge = ridge_reg.predict(X_test)
y_pred_ridge = np.clip(y_pred_ridge, 0, 100)

# MÃ©tricas
results['Ridge Regression'] = {
    'model': ridge_reg,
    'predictions': y_pred_ridge,
    'mse': mean_squared_error(y_test, y_pred_ridge),
    'rmse': np.sqrt(mean_squared_error(y_test, y_pred_ridge)),
    'mae': mean_absolute_error(y_test, y_pred_ridge),
    'r2': r2_score(y_test, y_pred_ridge),
    'time': ridge_time
}

# ============================================
# 4. COMPARAR MODELOS
# ============================================
print("\nğŸ“Š 4. COMPARAÃ‡ÃƒO DE MODELOS")
print("-"*80)

print("\n" + "="*95)
print(f"{'MODELO':<20} {'MSE':>12} {'RMSE':>12} {'MAE':>12} {'RÂ² SCORE':>12} {'TEMPO':>10}")
print("="*95)

for model_name, metrics in results.items():
    print(f"{model_name:<20} "
          f"{metrics['mse']:>12.4f} "
          f"{metrics['rmse']:>12.4f} "
          f"{metrics['mae']:>12.4f} "
          f"{metrics['r2']:>12.4f} "
          f"{metrics['time']:>9.2f}s")

print("="*95)

# Melhor modelo (menor RMSE)
best_model_name = min(results, key=lambda x: results[x]['rmse'])
best_model = results[best_model_name]['model']

print(f"\nğŸ† MELHOR MODELO: {best_model_name}")
print(f"   â€¢ RMSE: {results[best_model_name]['rmse']:.4f}")
print(f"   â€¢ MAE: {results[best_model_name]['mae']:.4f}")
print(f"   â€¢ RÂ²: {results[best_model_name]['r2']:.4f}")

# ============================================
# 5. ANÃLISE DE ERROS
# ============================================
print(f"\nğŸ” 5. ANÃLISE DE ERROS - {best_model_name}")
print("-"*80)

y_pred_best = results[best_model_name]['predictions']
errors = y_test - y_pred_best

print(f"\nğŸ“Š EstatÃ­sticas dos Erros:")
print(f"   â€¢ Erro mÃ©dio: {errors.mean():.4f}")
print(f"   â€¢ Erro absoluto mÃ©dio: {np.abs(errors).mean():.4f}")
print(f"   â€¢ Erro mÃ¡ximo: {np.abs(errors).max():.4f}")
print(f"   â€¢ Desvio padrÃ£o: {errors.std():.4f}")

# Percentis de erro
print(f"\nğŸ“ˆ DistribuiÃ§Ã£o de Erros Absolutos:")
for percentil in [50, 75, 90, 95, 99]:
    error_val = np.percentile(np.abs(errors), percentil)
    print(f"   â€¢ {percentil}Âº percentil: {error_val:.2f} pontos")

# ============================================
# 6. VISUALIZAÃ‡Ã•ES
# ============================================
print("\nğŸ“ˆ 6. GERANDO VISUALIZAÃ‡Ã•ES")
print("-"*80)

fig, axes = plt.subplots(2, 3, figsize=(18, 12))

# === GRÃFICO 1: ComparaÃ§Ã£o de Modelos ===
metrics_df = pd.DataFrame({
    'Modelo': list(results.keys()),
    'RMSE': [r['rmse'] for r in results.values()],
    'MAE': [r['mae'] for r in results.values()],
    'RÂ²': [r['r2'] for r in results.values()],
})

metrics_df.plot(x='Modelo', y=['RMSE', 'MAE'], kind='bar', ax=axes[0, 0], rot=15)
axes[0, 0].set_title('ComparaÃ§Ã£o de Erros', fontweight='bold', fontsize=12)
axes[0, 0].set_ylabel('Erro')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# === GRÃFICO 2: RÂ² Score ===
metrics_df.plot(x='Modelo', y='RÂ²', kind='bar', ax=axes[0, 1], 
                rot=15, color='coral', legend=False)
axes[0, 1].set_title('RÂ² Score', fontweight='bold', fontsize=12)
axes[0, 1].set_ylabel('RÂ²')
axes[0, 1].grid(True, alpha=0.3)
axes[0, 1].axhline(y=0, color='k', linestyle='--', linewidth=1)

# === GRÃFICO 3: Predito vs Real ===
axes[0, 2].scatter(y_test, y_pred_best, alpha=0.5, s=10)
axes[0, 2].plot([0, 100], [0, 100], 'r--', linewidth=2, label='Perfeito')
axes[0, 2].set_xlabel('Score Real')
axes[0, 2].set_ylabel('Score Predito')
axes[0, 2].set_title(f'Predito vs Real - {best_model_name}', fontweight='bold', fontsize=12)
axes[0, 2].legend()
axes[0, 2].grid(True, alpha=0.3)
axes[0, 2].set_xlim([0, 100])
axes[0, 2].set_ylim([0, 100])

# === GRÃFICO 4: DistribuiÃ§Ã£o de Erros ===
axes[1, 0].hist(errors, bins=50, edgecolor='black', alpha=0.7, color='steelblue')
axes[1, 0].axvline(x=0, color='r', linestyle='--', linewidth=2)
axes[1, 0].set_xlabel('Erro (Real - Predito)')
axes[1, 0].set_ylabel('FrequÃªncia')
axes[1, 0].set_title('DistribuiÃ§Ã£o de Erros', fontweight='bold', fontsize=12)
axes[1, 0].grid(True, alpha=0.3)

# === GRÃFICO 5: Erro Absoluto ===
abs_errors = np.abs(errors)
axes[1, 1].hist(abs_errors, bins=50, edgecolor='black', alpha=0.7, color='coral')
axes[1, 1].set_xlabel('Erro Absoluto')
axes[1, 1].set_ylabel('FrequÃªncia')
axes[1, 1].set_title('DistribuiÃ§Ã£o de Erros Absolutos', fontweight='bold', fontsize=12)
axes[1, 1].grid(True, alpha=0.3)

# === GRÃFICO 6: ResÃ­duos ===
axes[1, 2].scatter(y_pred_best, errors, alpha=0.5, s=10)
axes[1, 2].axhline(y=0, color='r', linestyle='--', linewidth=2)
axes[1, 2].set_xlabel('Score Predito')
axes[1, 2].set_ylabel('ResÃ­duo (Real - Predito)')
axes[1, 2].set_title('GrÃ¡fico de ResÃ­duos', fontweight='bold', fontsize=12)
axes[1, 2].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('models/regression/regression_analysis.png', dpi=300, bbox_inches='tight')
print("ğŸ’¾ GrÃ¡fico salvo: models/regression/regression_analysis.png")
plt.close()

# === GRÃFICO 7: Score por Categoria de Risco ===
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Categorizar scores
def categorize_risk(score):
    if score < 20:
        return 'Muito Baixo'
    elif score < 40:
        return 'Baixo'
    elif score < 60:
        return 'MÃ©dio'
    elif score < 80:
        return 'Alto'
    else:
        return 'Muito Alto'

risk_categories_real = [categorize_risk(s) for s in y_test]
risk_categories_pred = [categorize_risk(s) for s in y_pred_best]

# DistribuiÃ§Ã£o real
pd.Series(risk_categories_real).value_counts().sort_index().plot(
    kind='bar', ax=axes[0], color='steelblue', rot=45)
axes[0].set_title('DistribuiÃ§Ã£o Real de Risco', fontweight='bold', fontsize=12)
axes[0].set_ylabel('Quantidade')
axes[0].grid(True, alpha=0.3, axis='y')

# DistribuiÃ§Ã£o predita
pd.Series(risk_categories_pred).value_counts().sort_index().plot(
    kind='bar', ax=axes[1], color='coral', rot=45)
axes[1].set_title('DistribuiÃ§Ã£o Predita de Risco', fontweight='bold', fontsize=12)
axes[1].set_ylabel('Quantidade')
axes[1].grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.savefig('models/regression/risk_distribution.png', dpi=300, bbox_inches='tight')
print("ğŸ’¾ GrÃ¡fico salvo: models/regression/risk_distribution.png")
plt.close()

# ============================================
# 7. SALVAR MODELO
# ============================================
print(f"\nğŸ’¾ 7. SALVANDO MELHOR MODELO")
print("-"*80)

# Salvar modelo
model_path = 'models/regression/risk_predictor.pkl'
joblib.dump(best_model, model_path)
print(f"âœ… Modelo salvo: {model_path}")

# Salvar scaler de scores (para normalizaÃ§Ã£o)
score_info = {
    'min': float(y.min()),
    'max': float(y.max()),
    'mean': float(y.mean()),
    'std': float(y.std())
}

import json
model_info = {
    'model_name': best_model_name,
    'metrics': {
        'rmse': results[best_model_name]['rmse'],
        'mae': results[best_model_name]['mae'],
        'r2_score': results[best_model_name]['r2']
    },
    'score_info': score_info,
    'feature_names': X.columns.tolist()
}

with open('models/regression/model_info.json', 'w') as f:
    json.dump(model_info, f, indent=4)
print(f"âœ… InformaÃ§Ãµes salvas: models/regression/model_info.json")

# ============================================
# 8. EXEMPLOS DE PREDIÃ‡Ã•ES
# ============================================
print(f"\nğŸ§ª 8. EXEMPLOS DE PREDIÃ‡Ã•ES")
print("-"*80)

# Selecionar amostras de diferentes nÃ­veis de risco
sample_indices = []
for category in ['Muito Baixo', 'Baixo', 'MÃ©dio', 'Alto', 'Muito Alto']:
    category_indices = [i for i, cat in enumerate(risk_categories_real) if cat == category]
    if category_indices:
        sample_indices.append(np.random.choice(category_indices))

print("\nğŸ“‹ Exemplos de Scores de Risco:\n")
print(f"{'Score Real':<12} {'Score Predito':<15} {'Erro':<10} {'Categoria':<15}")
print("-"*60)

for idx in sample_indices:
    real = y_test.iloc[idx] if hasattr(y_test, 'iloc') else y_test[idx]
    pred = y_pred_best[idx]
    error = abs(real - pred)
    category = categorize_risk(real)
    
    print(f"{real:>6.2f}       {pred:>6.2f}          {error:>6.2f}     {category:<15}")

# ============================================
# 9. INTERPRETAÃ‡ÃƒO DOS SCORES
# ============================================
print("\n" + "="*80)
print(" "*25 + "INTERPRETAÃ‡ÃƒO DOS SCORES")
print("="*80)

print("""
ğŸ“Š CATEGORIAS DE RISCO:

   0-20:   ğŸŸ¢ MUITO BAIXO  - TransaÃ§Ã£o segura, processar normalmente
  20-40:   ğŸŸ¡ BAIXO        - Monitorar, baixa chance de fraude
  40-60:   ğŸŸ  MÃ‰DIO        - AtenÃ§Ã£o redobrada, verificar padrÃµes
  60-80:   ğŸ”´ ALTO         - ProvÃ¡vel fraude, revisar manualmente
  80-100:  ğŸš¨ MUITO ALTO   - Bloqueio imediato recomendado

ğŸ’¡ USO PRÃTICO:

   â€¢ Score < 40:  Aprovar automaticamente
   â€¢ Score 40-60: Solicitar verificaÃ§Ã£o adicional (2FA, SMS)
   â€¢ Score > 60:  Bloquear e avisar cliente
   â€¢ Score > 80:  Bloquear + investigaÃ§Ã£o de seguranÃ§a
""")

# ============================================
# 10. RESUMO FINAL
# ============================================
print("\n" + "="*80)
print(" "*25 + "RESUMO FINAL - REGRESSÃƒO")
print("="*80)

print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    RESULTADOS DO MODELO DE REGRESSÃƒO                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ ğŸ† MELHOR MODELO: {best_model_name:<48}       â•‘
â•‘                                                                       â•‘
â•‘ ğŸ“Š MÃ‰TRICAS DE DESEMPENHO:                                           â•‘
â•‘    â€¢ RMSE (Root Mean Squared Error): {results[best_model_name]['rmse']:>6.2f} pontos                   â•‘
â•‘    â€¢ MAE (Mean Absolute Error):      {results[best_model_name]['mae']:>6.2f} pontos                   â•‘
â•‘    â€¢ RÂ² Score:                       {results[best_model_name]['r2']:>6.2f} ({results[best_model_name]['r2']*100:>5.1f}% variÃ¢ncia explicada) â•‘
â•‘                                                                       â•‘
â•‘ ğŸ“ˆ ANÃLISE DE ERROS:                                                 â•‘
â•‘    â€¢ Erro mÃ©dio absoluto: {np.abs(errors).mean():>6.2f} pontos                              â•‘
â•‘    â€¢ 50% dos erros < {np.percentile(np.abs(errors), 50):>6.2f} pontos                              â•‘
â•‘    â€¢ 95% dos erros < {np.percentile(np.abs(errors), 95):>6.2f} pontos                              â•‘
â•‘                                                                       â•‘
â•‘ â±ï¸  TEMPO DE TREINAMENTO: {results[best_model_name]['time']:>6.2f}s                                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

print("\nğŸ’¡ O QUE SIGNIFICA:")
print("-"*80)
print(f"""
â€¢ RMSE ({results[best_model_name]['rmse']:.2f}): Em mÃ©dia, o erro Ã© de Â±{results[best_model_name]['rmse']:.1f} pontos no score
â€¢ MAE ({results[best_model_name]['mae']:.2f}): Erro absoluto mÃ©dio de {results[best_model_name]['mae']:.1f} pontos
â€¢ RÂ² ({results[best_model_name]['r2']:.2f}): O modelo explica {results[best_model_name]['r2']*100:.1f}% da variaÃ§Ã£o nos scores

ğŸ¯ INTEGRAÃ‡ÃƒO COM CLASSIFICAÃ‡ÃƒO:
   O modelo de regressÃ£o complementa o classificador fornecendo
   um score granular (0-100) ao invÃ©s de apenas Fraude/LegÃ­tima.
   Isso permite decisÃµes mais nuanceadas!

ğŸ¯ PRÃ“XIMO PASSO: Modelo de Clustering (Identificar padrÃµes de fraude)
""")

print("="*80)
print("âœ… MODELO DE REGRESSÃƒO CONCLUÃDO COM SUCESSO!")
print("="*80)
print("\nğŸš€ Execute agora: python src/04_clustering_model.py")
print("="*80)